{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMit5uJQsL2AiXVvPo4M28n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yneha70/IIITH/blob/main/Task_3_Object_Detection_and_Sementation_Video_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54izHuZP0D_X"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import subprocess\n",
        "from ultralytics import YOLO\n",
        "\n",
        "BASE_DIR = r\"C:\\Users\\Neha\\Desktop\\YOLO_Restaurant_Project\"\n",
        "input_video = os.path.join(BASE_DIR, \"input\", \"input_video.mp4\")\n",
        "frames_folder = os.path.join(BASE_DIR, \"frames\")\n",
        "output_frames_folder = os.path.join(BASE_DIR, \"output_frames\")\n",
        "final_output_video = os.path.join(BASE_DIR, \"output_video.mp4\")\n",
        "\n",
        "os.makedirs(frames_folder, exist_ok=True)\n",
        "os.makedirs(output_frames_folder, exist_ok=True)\n",
        "\n",
        "print(\" Extracting 24 frames per second from video...\")\n",
        "extract_cmd = [\n",
        "    r\"C:\\ffmpeg\\ffmpeg-7.1.1-essentials_build\\bin\\ffmpeg.exe\",\n",
        "    \"-i\", input_video,\n",
        "    \"-vf\", \"fps=24\",\n",
        "    os.path.join(frames_folder, \"frame_%04d.jpg\"),\n",
        "    \"-hide_banner\", \"-loglevel\", \"error\"\n",
        "]\n",
        "subprocess.run(extract_cmd)\n",
        "print(\" Frames extracted successfully and saved to:\", f\n",
        "print(\"\\n Running YOLO object detection on frames...\")\n",
        "model = YOLO(\"yolov8l-seg.pt\")\n",
        "CLASS_COLORS = {\n",
        "    \"person\": (0, 255, 0),\n",
        "    \"car\": (255, 0, 0),\n",
        "    \"truck\": (255, 128, 0),\n",
        "    \"bus\": (0, 255, 255),\n",
        "    \"motorbike\": (255, 0, 255),\n",
        "    \"bicycle\": (0, 128, 255),\n",
        "    \"traffic light\": (0, 0, 255),\n",
        "    \"stop sign\": (128, 0, 128),\n",
        "    \"dog\": (160, 82, 45),\n",
        "    \"cat\": (255, 105, 180),\n",
        "}\n",
        "\n",
        "DEFAULT_COLOR = (200, 200, 200)\n",
        "\n",
        "frame_files = sorted([f for f in os.listdir(frames_folder) if f.endswith((\".jpg\", \".png\"))])\n",
        "for idx, frame_name in enumerate(frame_files, start=1):\n",
        "    frame_path = os.path.join(frames_folder, frame_name)\n",
        "    img = cv2.imread(frame_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\" Skipping unreadable frame: {frame_name}\")\n",
        "        continue\n",
        "\n",
        "    results = model.predict(source=img, conf=0.25, save=False)\n",
        "\n",
        "    for box, cls in zip(results[0].boxes, results[0].boxes.cls):\n",
        "        class_id = int(cls)\n",
        "        class_name = model.names[class_id].lower()\n",
        "        conf = float(box.conf)\n",
        "        xyxy = [int(x) for x in box.xyxy.tolist()[0]]\n",
        "\n",
        "        color = CLASS_COLORS.get(class_name, DEFAULT_COLOR)\n",
        "        label = f\"{class_name.capitalize()} {conf:.2f}\"\n",
        "\n",
        "        cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, 2)\n",
        "\n",
        "        (text_w, text_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "        cv2.rectangle(img, (xyxy[0], xyxy[1] - text_h - 6),\n",
        "                      (xyxy[0] + text_w, xyxy[1]), color, -1)\n",
        "        cv2.putText(img, label, (xyxy[0], xyxy[1] - 4),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    output_path = os.path.join(output_frames_folder, f\"processed_{frame_name}\")\n",
        "    cv2.imwrite(output_path, img)\n",
        "    print(f\" Processed frame {idx}/{len(frame_files)}: {frame_name}\")\n",
        "\n",
        "print(\"\\n All frames processed and saved to:\", output_frames_folder)\n",
        "\n",
        "print(\"\\n Stitching processed frames into final output video...\")\n",
        "combine_cmd = [\n",
        "    r\"C:\\ffmpeg\\ffmpeg-7.1.1-essentials_build\\bin\\ffmpeg.exe\",\n",
        "    \"-framerate\", \"24\",\n",
        "    \"-i\", os.path.join(output_frames_folder, \"processed_frame_%04d.jpg\"),\n",
        "    \"-c:v\", \"libx264\",\n",
        "    \"-pix_fmt\", \"yuv420p\",\n",
        "    final_output_video,\n",
        "    \"-hide_banner\", \"-loglevel\", \"error\"\n",
        "]\n",
        "subprocess.run(combine_cmd)\n",
        "print(\" Output video created successfully at:\", final_output_video)\n",
        "print(\"\\n Task complete! You can now compare input and output videos.\")\n"
      ]
    }
  ]
}